
# Pipeline ETL ANTAQ com Apache Airflow

Este projeto implementa um pipeline ETL (Extract, Transform, Load) para processar dados da ANTAQ (AgÃªncia Nacional de Transportes AquaviÃ¡rios) utilizando Apache Airflow em containers Docker.

## ðŸ”§ PrÃ©-requisitos

- Docker
- Docker Compose
- Git
- Python 3.7+

## ðŸš€ ConfiguraÃ§Ã£o Inicial

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
```

### 2. ConfiguraÃ§Ã£o do Ambiente

Crie um arquivo `.env` na raiz do projeto com as seguintes variÃ¡veis:
```bash
env
Airflow
AIRFLOW_UID=50000
AIRFLOW_GID=0
AIRFLOW_USER=airflow
AIRFLOW_PASSWORD=airflow
AIRFLOW_DATABASE=airflow
PostgreSQL
POSTGRES_USER=airflow
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow
```
### 3. Estrutura de DiretÃ³rios

```bash
â”œâ”€â”€ docker/
â”‚ â””â”€â”€ constraints-3.7.txt
â”œâ”€â”€ src/
â”‚ â””â”€â”€ dags/
â”‚ â”œâ”€â”€ etl_pipeline_dag.py
â”‚ â””â”€â”€ antaq_classes.py
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ processed/
â”‚ â””â”€â”€ pre_processed/
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

### 4. InicializaÃ§Ã£o do Docker
Inicie todos os serviÃ§os
```bash
docker-compose up -d
```

### 5. Acessar o Airflow

1. Acesse a interface web:
   - URL: `http://localhost:8080`
   - Username: `airflow`
   - Password: `airflow123`
