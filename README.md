
# Pipeline ETL ANTAQ com Apache Airflow

Este projeto implementa um pipeline ETL (Extract, Transform, Load) para processar dados da ANTAQ (AgÃªncia Nacional de Transportes AquaviÃ¡rios) utilizando Apache Airflow em containers Docker.

## ðŸ”§ PrÃ©-requisitos

- Docker
- Docker Compose
- Git
- Python 3.7+

## ðŸš€ ConfiguraÃ§Ã£o Inicial

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
```

### 2. Estrutura de DiretÃ³rios

```bash
â”œâ”€â”€ docker/
â”‚ â””â”€â”€ constraints-3.7.txt
â”œâ”€â”€ src/
â”‚ â””â”€â”€ dags/
â”‚ â”œâ”€â”€ etl_pipeline_dag.py
â”‚ â””â”€â”€ antaq_classes.py
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ processed/
â”‚ â””â”€â”€ pre_processed/
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

### 3. InicializaÃ§Ã£o do Docker
Inicie todos os serviÃ§os
```bash
docker-compose up -d
```

### 5. Acessar o Airflow

1. Acesse a interface web:
   - URL: `http://localhost:8080`
   - Username: `airflow`
   - Password: `airflow123`
